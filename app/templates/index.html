<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
        <meta name="description" content="" />
        <meta name="author" content="" />
        <title>Predicting Credit Card Approvals</title>
        <link rel="icon" type="image/x-icon" href={{ url_for('static', filename='assets/favicon.ico') }} />
        <!-- Core theme CSS (includes Bootstrap)-->
        <link href={{ url_for('static', filename='css/styles.css') }} rel="stylesheet" />
    </head>
    <body id="page-top">
        <!-- Navigation-->
        <nav class="navbar navbar-expand-lg navbar-dark bg-dark fixed-top" id="mainNav">
            <div class="container px-4">
                <a class="navbar-brand" href="#page-top">Credit Card Approval Classifier</a>
                <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button>
                <div class="collapse navbar-collapse" id="navbarResponsive">
                    <ul class="navbar-nav ms-auto">
                        <li class="nav-item"><a class="nav-link" href="#project">Project Overview</a></li>
                        <li class="nav-item"><a class="nav-link" href="#EDA">EDA</a></li>
                        <li class="nav-item"><a class="nav-link" href="#ML">Machine Learning</a></li>
                        <li class="nav-item"><a class="nav-link" href="#Conclusion">Conclusion</a></li>
                    </ul>
                </div>
            </div>
        </nav>
        <!-- Header-->
        <header class="bg-primary bg-gradient text-white">
            <div class="container px-4 text-center">
                <h1 class="fw-bolder">Predicting Credit Card Approvals from Application Data</h1>
                <p class="lead">AI Camp Data Science Crash Course by Katherine Vo</p>
                <a class="btn btn-lg btn-light" href="#project">View project below!</a>
            </div>
        </header>
        <!-- Project overview section-->
        <section id="project">
            <div class="container px-4">
                <div class="row gx-4 justify-content-center">
                    <div class="col-lg-8">
                        <h2>Project Overview</h2>
                        <p class="lead">In this project, we will explore credit card application data. We will be building a classification model to predict the approval
                        of credit card applications based on the information, such as credit score and income, that the applicant provides. Our goal in this project will not only to 
                        predict approval rates, but to possibly to discover trends and confounding variables that could potentially impact our outcome. The dataset for this project was a cleaned 
                        version of a database from the UCI Machine Learning Repository.
                    
                        </p>
                    </div>
                </div>
            </div>
        </section>

        <!-- Exploratory Data Analysis section-->
        <section class="bg-light" id="EDA">
            <div class="container px-4">
                <div class="row gx-4 justify-content-center">
                    <div class="col-lg-8">
                        <h2>Exploratory Data Analysis</h2>
                        <hr/>
                        <p class = 'lead'> Because we don't have much information about all of the features and how they interact with one another, we will perform exploratory data analysis to understand these relationships further.
                        </p>
                        
                        <h4>Correlation Heatmap of all Features</h4>
                        <p> Firstly, I plotted a correlation heatmap to get an initial understanding of the relationship between all of our features and its correlation
                            with the rate of approval.
                        </p>
                        <iframe width="900" height="900" title="Correlation Table of Features" 
	                    src="{{ url_for('static', filename='correlation-heatmap.html')}}"></iframe> 
                        <p> Overall, all of features had positive correlations with the rate of approval, except for Gender and ZipCode.
                            Surprisingly, the  PriorDefault feature had the highest correlation rate with the approval rate. Initially, I hypothesized that features such as income and credit score
                            would be the most important features that contribute to getting approved, but income was among the factors that had a lower correlation (0.18) compared to Employed (0.46) and
                            the YearsEmployed (0.32). </p>

                        <h4> Visualizing Numerical Features</h4>
                        <p class = 'lead'> Firstly, we will take a deeper look into the distributions of our numerical features. This will aid us in cleaning and scaling our dataset, as well as choosing the 
                            most important features to include in our maching learning models.
                        </p>
                        
                        <img src = {{ url_for('static', filename='images/numerical-vars.png')}} alt = 'Numerical Features' width = 900 height = 400 />
                        <hr/>
                        <h4> Visualizing Categorical Features</h4>
                        <p class = 'lead'> Now, we will create subplots to see the distributions of all the categorical variables. </p>
                        
                        
                        <img src = {{ url_for('static', filename='images/categorical-vars.png')}} alt = 'Categorical Features' width = 900 height = 400/>
                        <hr/>
                        <p class = 'lead'> Then, we will plot countplots of each of these features in relation to the overall approval rates.</p>
                        <i> Please note that 0 and 1 refer to rejected and approved applications, respectively.</i>
                        <img src = {{ url_for('static', filename='images/categorical-app.png')}} alt = 'Categorical vs. Approval' width = 900 height = 300 />
                        <hr/>
                        <p> Because industry does not seem to have a strong impact on the approval rate, we will be excluding this from our machine learning models. This is also the case with the citizen feature. However, I think it would be important to include the ethnicity feature for our approval classification. It brings up an additional hypothesis that ethnicity could have a possible impact on the approval of credit card applications which bring up more significant questions of racial bias in the application process.
                        </p>

                        <hr/>
                        <h4> Visualizing Binary Variables</h4>
                        <p class = 'lead'> Next, let's take a deeper look into specifically the binary categorical variables. Below, I plotted the counts of each of these variables in relation to the overall approval rate.</p>
                    
                        <img src = {{ url_for('static', filename='images/binary-vars.png')}} alt = 'Binary Categorical Variables' width = 900 height = 400/> 
                        <hr/>
                        <p> After looking at the plots above, we can see that the PriorDefault and Employed features have a major impact on whether or not an applicant
                            gets approved for a credit card. These will be significant factors for developing our classification models. On the other hand, we can see that features, such as Gender and Driver's License, have similar distributions
                            whether the applicant gets rejected or approved.
                        </p>
                        <hr/>
                        <h4> Approval Based on Ethicity and Gender </h4>
                        <p class = 'lead'> Lastly, I wanted to visualize the relationship between Ethnicity, Gender, and the approval rate. One of my initial hypotheses was that there would be a significant relationship between these two features
                            and getting approved for a credit card.</p>
                        <img src = {{ url_for('static', filename='images/ethnicity-gender.png')}} alt = 'Ethnicity-Gender' />
                        <hr/>
                        <p> My hypothesis was that different socioeconomic statuses and biases would create a disproportionate impact on credit card approval. However from this dataset, there are 
                            not enough data points that would be representative of the population, so I will not be including either of these features in my machine learning models.
                        </p>
                        <hr/>
                        <h3> Correlation Heatmap of Crucial Features</h3>
                        <p class = 'lead'> Now, that I have condensed my features, let's plot a correlation heatmap of these features before developing our models.</p> 
                        <iframe width="900" height="900" title="Correlation Table of Crucial Features" 
	                    src={{ url_for('static', filename='c-map2.html')}}></iframe> 

                    </div>
                </div>
            </div>
        </section>

        <!-- ML section-->
        <section id="ML">
            <div class="container px-4">
                <div class="row gx-4 justify-content-center">
                    <div class="col-lg-8">
                        <h2>Machine Learning Models</h2>
                        <hr/>
                        <h4> Logisitic Regression: Explanation </h4> 
                        <p class = 'lead'> First, we will be implementing logistic regression to predict our binary outcome of whether or not an application is approved. 
                            Logistic regression is meant to model the probability of a dependent outcome (getting approved) based on a set of independent variables (our features)
                            using an underlying logistic function. These predicted probabilities must be transformed binary values in order make a valid prediction, which is the purpose of 
                            our logistic or sigmoid function.  </p>
                        <img src = {{ url_for('static', filename='images/lr-info.png')}} alt = 'LR Info' />
                        <hr/>
                        <h4> Logistic Regression: Results</h4>
                        <p class = 'lead'> Below, I plotted a confusion matrix of our logisitic regression classfication model.</p>
                        <iframe width="500" height="500" title="Confusion Matrix for LR" 
	                    src={{ url_for('static', filename='cf-lr.html')}}></iframe> 
                        <hr/>
                        <p class = 'lead'> This model performed very well on this dataset with an accuracy of approximately 84%
                            The mean absolute error was 0.162. From the confusion matrix, there was a much higher rate of false positive predictions than false negatives.</p>
                        <hr/>
                        <h4> k-Nearest Neighbors: Explanation</h4>
                        <p class = 'lead'> Next, we implemented a k-Nearest Neighbors classifier. In this type of classification model, we classify our outcome based on what group the
                            labeled input data is in. It will look at a number (k) of points that are closest to the current point (application) and use the classification of the k points to determine the outcome of the point.
                        </p>

                        <img src = {{ url_for('static', filename='images/knn-info.png')}} alt = 'knn info'/>
                        <hr/>

                        <h4> k-Nearest Neighbors: Results</h4>
                        <p class = 'lead'> Below, I plotted a confusion matrix of our k-Nearest Neighbors classfication model.
                            From the confusion matrix, there was a moderate amount of error with a higher amount of false negatives than false positives.
                        </p>
                        <iframe width="500" height="500" title="Confusion Matrix for k-nn" 
	                    src={{ url_for('static', filename='cf-knn.html')}}></iframe> 
                        <hr/>
                        <p class = 'lead'> For this classification model, it had a 72.3% accuracy rate, with a mean absolute error of 0.277. </p>
                        <hr/>
                        <h4> Random Forests: Explanation</h4>
                        <p class = 'lead'> Our last machine learning model that we implemented is Random Forest. In a random forest, we will implement many decision trees on different samples
                            of our dataset. It will then take the average of all of those decision trees to give us our final prediction. Random forests produce higher accuracy rates than
                        decision trees by themselves due to its ability to prevent overfitting and limiting bias error. </p>
                        <img src = {{ url_for('static', filename='images/rf-info.png')}} alt = 'RF info' />
                        <hr/>
                        <h4> Random Forests: Results</h4>
                        <p class = 'lead'> Below, I plotted the confusion matrix of our Random Forest model.</p>
                        <iframe width="500" height="500" title="Confusion Matrix for RF" 
	                    src={{ url_for('static', filename='cf-rf.html')}}></iframe> 
                        <hr/>
                        <p class = 'lead'> This model performed the best out of all of our ML models with an accuracy of 86.1% with
                            a mean absolute error of 0.144. From the confusion matrix, there was a higher amount of false negatives than false positives. 
                        </p>
            
                    </div>
                </div>
            </div>
        </section>
         <!-- Conclusion section-->
         <section class="bg-light" id="Conclusion">
            <div class="container px-4">
                <div class="row gx-4 justify-content-center">
                    <div class="col-lg-8">
                        <h2>Conclusion</h2>
                        <p class="lead"> In conclusion, our random forest classification model performed best out of all of our machine learning models. 
                            I do believe that this method is best for this particular dataset because of its ability to limit bias error that could occur due to
                            the small and limited dataset. It is also less prone to overfitting in comparison to logisitic regression and k-nearest neighbors.

                        <h4> So what? </h4>
                        <p class = 'lead'> This project is a great first step into understanding what features contribute most to credit card approvals. However, our models
                            were based on a small amount of data that is most likely not representative of the entire population. Some next steps would be to collect more data 
                            that could be more generalizable to different populations. With more research and data, this project could potentially be applied to simplyfying online
                            credit applications to make it less prone to bias. In addition to this, it could help explain certain ambiguities towards the public 
                            about what specific factors could aid them in increasing their chances of approval and make the whole process more accessible to a diverse population.
                        </p>

                        </p>
                    </div>
                </div>
            </div>
        </section>
        <!-- Footer-->
        <footer class="py-5 bg-dark">
            <div class="container px-4"><p class="m-0 text-center text-white">Copyright &copy; Your Website 2022</p></div>
        </footer>
        <!-- Bootstrap core JS-->
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>
        <!-- Core theme JS-->
        <script src="/static/js/scripts.js"></script>
    </body>
</html>
